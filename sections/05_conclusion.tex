\section{Conclusion}
\label{sec:conclusion}
We presented a comprehensive high-performance computing implementation for solving the Futoshiki puzzle, demonstrating the feasibility of solving an instance of an NP-hard by employing several different techniques, starting from the search space reduction via precoloring, and later on moving towards MPI, OMP and Hybrid solutions.


We have to note that when gathering data from the runs, we have noticed some discrepancies w.r.t. the execution times, and this is most likely dependent from the fact that older machine with the same node category (c-nodes) might have different hardware, or there is some wear and tear damage performed. Another factor is also due to the fact that the scheduler and the timing of when some jobs are scheduled might incur in some variance over the expected finishing time of our solutions. 

We have also noted that there were some differences in the time required to get results since the changes done in august to the hpc, which caused some processes which were able to finish before this update was rolled out to not finish at times.

\subsection{Key Achievements}
Our implementation achieves significant performance improvements at multiple levels:. As always, we are evaluating those results in the specific instance proposed in the evaluation section, so these numbers are for this case, but they shall serve as a rule of thumb for how much the speedup can be.

\begin{enumerate}
    \item \textbf{Algorithmic Optimization:} We have seen that pre-coloring phase, based on list coloring theory, reduces the search space by 70-90\%, providing a 59× speedup over naive backtracking. This optimization is crucial for making puzzles which have a bigger search space tractable also with a sequential solution, and therefore we opted to apply in every subsequent experiment.
    
    \item \textbf{Parallel Scalability:} We successfully parallelized the solver using three distinct paradigms. Here are the execution time findings:
    \begin{itemize}
        \item \textbf{OpenMP} achieves up to 53.4× speedup on 64 threads with minimal code complexity compared to the sequential solution.
        \item \textbf{MPI} demonstrates 123× speedup when using 128 processes. From our Speedup analysis it also slightly beat the OMP solution and therefore was also the best for the efficiency parameter. This means that, while the OMP solution is the easier one to implement compared to the MPI version, it also suffers more from memory contention and mutex or lock-like structures needed to perform syanchronization.
        \item \textbf{Hybrid MPI+OpenMP} reaches 60.4× speedup when using 32 CPUs and 8 threads, which showcases how leveraging MPI is actually the best solution compared to the other hybrid configurations. This was expected as the MPI only solution is already slightly better than OMP. An interesting finding is that while the Hybrid does not perform as good as the MPI only overall, there are still cases in which its configurability can lead to better results compared to our test under analysis.
    \end{itemize}
    
    \item \textbf{Configurable Performance:} The task generation factor allows fine-tuning for specific hardware configurations and puzzle characteristics, with 64 factor leading up to \textbf{3.5x} speedup over the baseline (factor set to 1, which means we are not oversubscribing anything).

    \item \textbf{Scalability Analysis}: the Strong analysis lead us to understanding that MPI achieves almost linear speedups and retains higher efficiency, making it the best solution if we are aiming at maximizing that parameter. We have also seen that, due to the fact that it is hard to determine a priori how complex a puzzle can be to solve given only its size, it does not make sense to proceed with the Weak scalability analysis.
\end{enumerate}


Overall we can therefore say that the speedup performed by the list coloring algorithm in order to precolor the solution is extremely important, that in our evaluated instance MPI outperforms OMP and the hybrid solution, while at times it introduces some overhead due to the message passing and shared memory synchronization, therefore decrementing the efficiency at higher computational units selected, still serves as a fairly interesting solution due to its extreme configuratbility. This does not mean that the OMP solution is bad as a whole, what we are stating is that the other two solutions outperform it, but still is an extremely useful entry point due to its ease of implementation, as it requires little work to transform some sequential algorithms to parallel ones.

Other than the Futoshiki instance itself, one could easily see how this can be adapted to a Sudoku Solver, a generalized version for Graph Coloring, Scheduling problems and of course, even with some overhead to convert the problem instance, also for general SAT solving or SMT solving strategies.
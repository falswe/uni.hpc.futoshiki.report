\section{Solution Proposed}
\label{sec:solution}

We now present our findings and solutions in solving Futoshiki puzzle. We start in \Cref{subsec:paper_implementation} by first understanding how the sequential algorithm proposed by Şen and Diner in \cite{Sen2024Futoshiki} work. In this section we dive into how the precoloring works in \Cref{par:precoloring} and we wrap up by understanding how the backtrack with CSP helps us solve the problem in \Cref{par:backtrack_with_csp}

After having obtained what is going to become our baseline in the validation, we move towards the parallel implementations in \Cref{subsec:parallel_implementation}: we start off by understanding how the dynamic load balancing works in \Cref{par:dynamic_load_balancing}, as it is a sophisticated algorithm at the base of every parallel implementation. We then move towards the MPI implementation in \cref{par:mpi_implementation}, then to the OpenMP implementation in \cref{par:omp_implementation} and finally to the hybrid implementation in \cref{par:hybrid_implementation}.

\subsection{Implementing The Sequential Algorithm}
\label{subsec:paper_implementation}
Our implementation builds upon the list coloring transformation detailed in \cite{Sen2024Futoshiki}. This approach significantly outperforms naive backtracking by reducing the search space through constraint propagation before the recursive search begins.

\paragraph{Pre-coloring: Search Space Reduction}
\label{par:precoloring}
The pre-coloring phase, implemented in \texttt{compute\_pc\_lists}, computes a "possible color list" (pc\_list) for each cell through iterative constraint propagation:

\begin{enumerate}
    \item \textbf{Initialization:} Empty cells receive pc\_lists containing all values 1 to N. Pre-filled cells contain only their given value.
    
    \item \textbf{Inequality Filtering:} The \texttt{filter\_possible\_colors} function removes values that violate inequality constraints. For instance, if cell A > cell B and B's pc\_list = \{1, 2\}, then A cannot contain values $\leq$ 2.
    
    \item \textbf{Uniqueness Propagation:} When a cell's pc\_list reduces to a single value, \texttt{process\_uniqueness} removes that value from all other cells in the same row and column.
    
    \item \textbf{Iteration:} Steps 2-3 repeat until no further reductions occur, ensuring maximal constraint propagation.
\end{enumerate}

This process often eliminates 70-90\% of possible values, dramatically reducing the search space complexity from $O(N^{N^2})$ to a much smaller effective branching factor.

\paragraph{Backtracking with Constrained Search}
\label{par:backtrack_with_csp}
After pre-coloring, the recursive backtracking function \texttt{seq\_color\_g} explores only values in each cell's reduced pc\_list:

\begin{lstlisting}[language=C, caption=Sequential backtracking core]
bool seq_color_g(Futoshiki* puzzle, 
                 int solution[MAX_N][MAX_N], 
                 int row, int col) {
    if (row >= puzzle->size) return true;
    if (col >= puzzle->size) 
        return seq_color_g(puzzle, solution, 
                          row + 1, 0);
    
    if (puzzle->board[row][col] != EMPTY) {
        solution[row][col] = 
            puzzle->board[row][col];
        return seq_color_g(puzzle, solution, 
                          row, col + 1);
    }
    
    for (int i = 0; 
         i < puzzle->pc_lengths[row][col]; i++) {
        int color = puzzle->pc_list[row][col][i];
        if (safe(puzzle, row, col, 
                 solution, color)) {
            solution[row][col] = color;
            if (seq_color_g(puzzle, solution, 
                           row, col + 1))
                return true;
            solution[row][col] = EMPTY;
        }
    }
    return false;
}
\end{lstlisting}

The \texttt{safe} function validates that a color assignment doesn't violate Latin Square constraints or inequality relationships with already-placed neighbors. This combination of pre-coloring and constrained backtracking forms our efficient sequential baseline.

\subsection{Parallel Design and Implementation}
\label{subsec:parallel_implementation}
we have to fill this
\sd{mark here}

\paragraph{Multi-Level Work Generation Framework}
\label{par:dynamic_load_balancing}
All three parallel implementations share a sophisticated work generation strategy implemented in \texttt{parallel.c}. This framework dynamically determines the optimal depth for creating work units based on the target number of parallel workers.

\begin{lstlisting}[language=C, caption=Dynamic depth calculation]
int calculate_distribution_depth(
    Futoshiki* puzzle, int num_workers) {
    int empty_cells[MAX_N * MAX_N][2];
    int num_empty = find_empty_cells(
        puzzle, empty_cells);
    
    for (int d = 1; d <= num_empty; d++) {
        long long job_count = 
            count_valid_assignments_recursive(
                puzzle, solution, empty_cells, 
                num_empty, 0, d);
        
        if (job_count > num_workers) {
            log_info("Depth %d generates %lld units", 
                     d, job_count);
            return d;
        }
    }
    return num_empty;
}
\end{lstlisting}

The algorithm explores the search tree to progressively deeper levels until generating sufficient work units. Each work unit represents a partial solution—a specific path through the initial portion of the search tree. This approach ensures:
\begin{itemize}
    \item \textbf{Load Balance:} Sufficient work units to keep all workers busy
    \item \textbf{Granularity Control:} Work units neither too large (causing imbalance) nor too small (increasing overhead)
    \item \textbf{Adaptability:} Automatic adjustment based on puzzle difficulty and worker count
\end{itemize}

\paragraph{MPI Implementation: Master-Worker Paradigm}
\label{par:mpi_implementation}
The MPI solver implements a distributed master-worker model suitable for cluster environments:

\begin{enumerate}
    \item \textbf{Master Process (Rank 0):}
    \begin{itemize}
        \item Broadcasts puzzle to all workers
        \item Generates and manages work unit pool
        \item Distributes work on demand
        \item Collects solutions and coordinates termination
    \end{itemize}
    
    \item \textbf{Worker Processes (Ranks 1 to P-1):}
    \begin{itemize}
        \item Request work units from master
        \item Apply partial solutions and continue search
        \item Report solutions back to master
    \end{itemize}
\end{enumerate}

The communication protocol uses tagged messages for clarity:

\begin{lstlisting}[language=C, caption=MPI communication tags]
typedef enum {
    TAG_WORK_REQUEST = 1,
    TAG_SOLUTION_FOUND = 2,
    TAG_SOLUTION_DATA = 3,
    TAG_TERMINATE = 4,
    TAG_WORK_ASSIGNMENT = 5
} MessageTag;
\end{lstlisting}

This design enables dynamic load balancing—workers request work only when ready, automatically handling heterogeneous performance and variable work unit difficulty.


\paragraph{OpenMP Implementation: Task-Based Parallelism}
\label{par:omp_implementation}
Our OpenMP solver leverages task-based parallelism for shared-memory systems. After generating work units, the master thread spawns OpenMP tasks that are dynamically scheduled across available threads:

\begin{lstlisting}[language=C, caption=OpenMP task generation]
#pragma omp parallel
{
    #pragma omp single
    {
        for (int i = num_work_units - 1; 
             i >= 0 && !found_solution; i--) {
            #pragma omp task firstprivate(i) \
                        shared(found_solution)
            {
                if (!found_solution) {
                    int local_solution[MAX_N][MAX_N];
                    apply_work_unit(puzzle, 
                        &work_units[i], local_solution);
                    
                    if (seq_color_g(puzzle, 
                        local_solution, 
                        start_row, start_col)) {
                        #pragma omp critical
                        {
                            if (!found_solution) {
                                found_solution = true;
                                memcpy(solution, 
                                    local_solution, 
                                    sizeof(local_solution));
                            }
                        }
                    }
                }
            }
        }
        #pragma omp taskwait
    }
}
\end{lstlisting}

Key features include:
\begin{itemize}
    \item \textbf{Dynamic Scheduling:} OpenMP runtime automatically balances tasks across threads
    \item \textbf{Early Termination:} Shared flag enables immediate termination upon solution discovery
    \item \textbf{Configurable Factor:} Task generation multiplier allows performance tuning
\end{itemize}

\paragraph{Hybrid Implementation: Combining MPI and OpenMP}
\label{par:hybrid_implementation}
The hybrid solver exploits both distributed and shared memory parallelism:

\begin{itemize}
    \item \textbf{Inter-node:} MPI distributes coarse-grained work units across nodes
    \item \textbf{Intra-node:} OpenMP further parallelizes each work unit within a node
\end{itemize}

\begin{lstlisting}[language=C, caption=Hybrid worker with nested parallelism]
static void hybrid_worker(Futoshiki* puzzle) {
    WorkUnit work_unit;
    MPI_Status status;
    
    while (true) {
        // Request work from master via MPI
        MPI_Send(&request, 1, MPI_INT, 0, 
                 TAG_WORK_REQUEST, MPI_COMM_WORLD);
        MPI_Recv(&work_unit, sizeof(WorkUnit), 
                 MPI_BYTE, 0, MPI_ANY_TAG, 
                 MPI_COMM_WORLD, &status);
        
        if (status.MPI_TAG == TAG_TERMINATE) break;
        
        // Apply work unit and solve with OpenMP
        Futoshiki sub_puzzle;
        memcpy(&sub_puzzle, puzzle, sizeof(Futoshiki));
        apply_work_unit(&sub_puzzle, &work_unit, 
                       sub_puzzle.board);
        
        if (omp_solve(&sub_puzzle, local_solution)) {
            // Report solution via MPI
            MPI_Send(&found_flag, 1, MPI_INT, 0, 
                    TAG_SOLUTION_FOUND, MPI_COMM_WORLD);
            MPI_Send(local_solution, MAX_N * MAX_N, 
                    MPI_INT, 0, TAG_SOLUTION_DATA, 
                    MPI_COMM_WORLD);
            break;
        }
    }
}
\end{lstlisting}

This two-level approach maximizes resource utilization on modern HPC clusters where nodes contain many cores. The implementation carefully manages the task generation factors at both levels to prevent oversubscription while ensuring sufficient parallelism.§
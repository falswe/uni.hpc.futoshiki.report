\section{Related Work}
\label{sec:related_work}
As our work builds upon and extends the solutions presented in the Futoshiki paper, in order for the reader to have a better understanding on the terminologies and techniques used, in this section we present all of the necessary relevant informations, also proposing how our solution is going to impact and build upon the state of the art (or concepts) presented in each subsection. 

We start in \Cref{subsec:csp} by giving an explanation of the Constraint Satisfaction and Propagation. In \Cref{subsec:backtrack} then move towards a brief recap of how backtrack can be leveraged to solve this problem. We continue in explaining how MPI and OMP are used in 'Irregular Problems' in \Cref{subsec:mpi_omp_irregular_problems}. We move to an high level view of the state of puzzle solving algorithms in \Cref{subsec:puzzle_solving_algorithms}. We then wrap up by presenting how load balancing is used in parallel computing in \Cref{subsec:load_balancing_in_parallel_computing} and also some considerations in the implications of leveraging HPC in the era of AI in \Cref{subsec:hpc_in_ai}.

\subsection{Constraint Satisfaction and Propagation}
\label{subsec:csp}
The foundation of our approach lies in constraint propagation techniques: After Adamu-Fika showed in \cite{sudoku_csp} that it is possible to transform Sudoku leveraging CSP, Norvig's work on Sudoku solving \cite{NorvigSudoku} demonstrated the power of constraint propagation combined with search, achieving several fold speedups over naive backtracking. Our pre-coloring phase extends these ideas specifically for Futoshiki's inequality constraints.

The transformation of Futoshiki into a list coloring problem, as proposed by Şen and Diner \cite{Sen2024Futoshiki}, provides the theoretical foundation for our implementation. Their work showed that viewing the puzzle through the lens of graph coloring enables more sophisticated pruning strategies compared to naive backtracking strategies. Our work therefore starts from here, by implementing their sequential algorithm proposed in this paper, in order to construct a base reference for our solutions. We then follow up by implementing parallel solving strategies such as MPI, OMP, and an hybrid solution.


One might ask himself "Why do we need to parallalize this problem if there is already a linear solution?". The response is quite straightforward: after Colbourn's work \cite{Colbourn1984} on the complexity of Latin Square completion established the NP-completeness of the problem class, he followed up by motivating the need for efficient heuristics and parallel approaches. Haraguchi and Ono \cite{Haraguchi2014} further analyzed the approximability of Latin Square completion puzzles, providing insights into the theoretical limits of polynomial-time algorithms.

\subsection{Parallel Backtracking and Search}
\label{subsec:backtrack}
Parallel constraint satisfaction has been extensively studied, with various approaches proposed for distributing the search space. The book by Pacheco \cite{Pacheco2011} provides comprehensive coverage of parallel programming patterns, including the master-worker paradigm we employ in the MPI solution, and of course also in the hybrid approach. However, most existing work uses \textit{static work distribution}, whereas our \textit{dynamic multi-level approach} better handles the irregular search space of Futoshiki.
Let us take some moments to assess this statement.
In Sudoku the placement of the constraints is fixed, with a repeating pattern; boxes are identical in shape and size and the \textit{latin square} rule leads to an \textit{all different} constraint. It is easy to see how having fixed rules and symmetric properties leads to well defined search space reduction.

On the other side, Futoshiki introduces the aforementioned inequalities constraints. Due to the fact that they are placed \textit{between} cells, and due to the fact that their position is \textit{arbitrary}, this leads to having a search space reduction which is less efficient, as several assumptions made in Sudoku do not hold.

Research on parallel backtracking typically focuses on either shared-memory or distributed-memory systems in isolation. Among our contributions, we have developed a method which combines both paradigms and demonstrates that hybrid approaches can outperform single-paradigm solutions for irregular workloads.

\subsection{MPI and OpenMP for Irregular Problems}
\label{subsec:mpi_omp_irregular_problems}
The MPI standard \cite{MPIForum2021} and OpenMP specification \cite{OpenMP2020} provide the foundation for our parallel implementations. Gropp et al. \cite{Gropp1999} discuss various MPI programming patterns, including the master-worker model we adapt for dynamic load balancing.

Rabenseifner et al. \cite{Rabenseifner2009} specifically address hybrid MPI/OpenMP programming, analyzing the benefits and challenges of combining both paradigms. Their work on multi-core clusters directly influenced our hybrid implementation design. We extend their findings by demonstrating that careful management of task \textit{generation factors} to decide whether to rely more on MPI or open mp is crucial for optimal performance.

\subsection{Puzzle Solving Algorithms}
\label{subsec:puzzle_solving_algorithms}
Beyond Sudoku, various researchers have tackled different puzzle types with parallel algorithms, and the main outcome of these algorithms proposed is that the general approach of combining constraint propagation with parallel search is effective across multiple domains. However, most work focuses on puzzles with uniform constraints (like Sudoku's boxes), whereas Futoshiki's arbitrary inequalities presented in \Cref{futoshiki_inequalities} present unique challenges.

Our work differs from existing puzzle solvers in several key aspects:
\begin{itemize}
    \item \textbf{Multi-paradigm approach:} We systematically compare three parallelization strategies.
    \item \textbf{Dynamic depth calculation:} Our work generation adapts to available parallelism to define up to which color a pre-solving strategy can be applied.
    \item \textbf{Configurable granularity:} The \textit{task factor} mechanism in assessing the ratio among available work units and sub problems which are generated allow performance tuning without code changes.
    \item \textbf{Comprehensive evaluation:} We provide detailed analysis of both strong and weak scaling.
\end{itemize}

\subsection{Load Balancing in Parallel Computing}
\label{subsec:load_balancing_in_parallel_computing}
Load balancing for irregular problems remains an active research area. Static approaches suffer from load imbalance when work units have varying difficulty, while dynamic approaches usually face communication overhead. Our solution strikes a balance by generating sufficient work units upfront (based on the calculated depth) while using on-demand distribution to handle variability.

The concept of oversubscription, it being creating more tasks than workers is well-established in parallel computing. We are also going to present a study of the task generation factor's impact on performance, showing that 4-8× oversubscription optimally balances parallelism with overhead for constraint satisfaction problems.
\sd{this goes into the evaluation part, we cannot present results here}

\subsection{High-Performance Computing for AI}
\label{subsec:hpc_in_ai}
Due to the hype surrounding AI, the intersection of HPC and it has gained significant attention over the recent years. While much focus is on machine learning, combinatorial optimization and constraint satisfaction remain important applications. Our work demonstrates that traditional AI techniques like backtracking can benefit substantially from modern parallel computing infrastructure.

\sd{check this out -- if it is good, I have the bibtex ready}

Beyond machine learning, many real-world problems in science and industry can be formulated as large-scale combinatorial optimization or constraint satisfaction problems (CSPs), where backtracking-based search remains a competitive solution strategy. For example, airline crew scheduling — assigning thousands of crew members to flights while respecting legal rest, skill, and pairing constraints — has been accelerated using parallelized branch-and-bound algorithms, reducing solution times from hours to minutes on HPC clusters [Abdel-Basset et al., 2020]. In astronomy, the Hubble Space Telescope scheduling problem involves satisfying complex orbital, resource, and priority constraints; parallel constraint propagation has enabled near real-time generation of feasible schedules [Johnston \& Miller, 1994]. Even in recreational domains, CSP benchmarks such as Sudoku have served as scalable testbeds for massively parallel backtracking, achieving over 100× speedups on GPU-based systems [Matsumoto et al., 2013]. These examples illustrate that traditional AI techniques can benefit substantially from modern parallel computing infrastructure, enabling the solution of problems previously deemed intractable.


\sd{also here, this is part of the findings and we cannot showcase here}
The scalability results we achieve (up to 28× speedup on 64 cores) are competitive with other parallel constraint solvers, while our modular design facilitates adaptation to other problems. This positions our framework as a valuable contribution to both the HPC and AI communities.